{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e034071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca16902",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17b5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('h1', class_='entry-title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9df5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = soup.find('div', class_='td-post-content').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c980633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.\n",
      "Article Text: \n",
      "We have seen a huge development and dependence of people on technology in recent years. We have also seen the development of AI and ChatGPT in recent years. So it is a normal thing that we will become fully dependent on technology by 2040. Information technology will be a major power for all the developing nations. As a member of a developing nation, India is rapidly growing its IT base. It has also grown some IT cities which will be the major control centres for Information technology by 2040.\n",
      "Rising IT cities\n",
      "\n",
      "Noida:- Noida in Uttar Pradesh near New Delhi is an emerging IT sector now. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Noida has a market base of billions of dollars and is doing a great job of boosting the national economy. The establishment of so many software companies has made Noida an information technology hub.\n",
      "Gurgaon:- Gurgaon in Haryana is also an emerging IT hub. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Gurgaon has a market base of billions of dollars and is doing a great job of boosting the national economy.\n",
      "Bengaluru:- Bengaluru is called as the IT hub of India. It is also a smart city. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Bengaluru has a market base of billions of dollars and is doing a great job of boosting the national economy.\n",
      "\n",
      "Kolkata:- Kolkata in West Bengal is an \n"
     ]
    }
   ],
   "source": [
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08775a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files from\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    positive_words = file.read().splitlines()\n",
    "\n",
    "with open('negative-words.txt', 'r') as file:\n",
    "    negative_words = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2abcee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accessable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c889046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a53365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3496bd11",
   "metadata": {},
   "source": [
    "# Positive score,neg score without discarding stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec39c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_before_sw = word_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a1b0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'have',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'development',\n",
       " 'and',\n",
       " 'dependence',\n",
       " 'of',\n",
       " 'people',\n",
       " 'on',\n",
       " 'technology',\n",
       " 'in',\n",
       " 'recent',\n",
       " 'years',\n",
       " '.',\n",
       " 'We',\n",
       " 'have',\n",
       " 'also',\n",
       " 'seen']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_before_sw[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2790fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 44\n",
      "Negative Score: 6\n"
     ]
    }
   ],
   "source": [
    "positive_words_set = set(positive_words)\n",
    "negative_words_set = set(negative_words)\n",
    "\n",
    "positive_score = sum(1 for word in words_before_sw if word.lower() in positive_words_set)\n",
    "negative_score = sum(1 for word in words_before_sw if word.lower() in negative_words_set)\n",
    "\n",
    "print(\"Positive Score:\", positive_score)\n",
    "print(\"Negative Score:\", negative_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe2b38",
   "metadata": {},
   "source": [
    "# REMOVE STOP WORDS AND DOING THE SAME THING ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c4f094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "956f5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b17af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "words = word_tokenize(article_text)\n",
    "words_after_sw = [word for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57fd9020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seen',\n",
       " 'huge',\n",
       " 'development',\n",
       " 'dependence',\n",
       " 'people',\n",
       " 'technology',\n",
       " 'recent',\n",
       " 'years',\n",
       " '.',\n",
       " 'also',\n",
       " 'seen',\n",
       " 'development',\n",
       " 'AI',\n",
       " 'ChatGPT',\n",
       " 'recent',\n",
       " 'years',\n",
       " '.',\n",
       " 'normal',\n",
       " 'thing',\n",
       " 'become']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##we can see punctuation is not discarded while removing stop words...\n",
    "words_after_sw[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367b0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 44\n",
      "Negative Score: 6\n"
     ]
    }
   ],
   "source": [
    "positive_score_aftersw = sum(1 for word in words_after_sw if word.lower() in positive_words_set)\n",
    "negative_score_aftersw = sum(1 for word in words_after_sw if word.lower() in negative_words_set)\n",
    "\n",
    "print(\"Positive Score:\", positive_score_aftersw)\n",
    "print(\"Negative Score:\", negative_score_aftersw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e99131f",
   "metadata": {},
   "source": [
    "# POLARITY SCORE and SUBJECTIVITY SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity Score: 0.7599999848000003\n",
      "Subjective Score: 0.06305170231645435\n"
     ]
    }
   ],
   "source": [
    "polarity_score = (positive_score_aftersw - negative_score_aftersw) / (positive_score_aftersw + negative_score_aftersw + 0.000001)\n",
    "\n",
    "subjectivity_score = (positive_score_aftersw +  negative_score_aftersw)/ (len(words_after_sw) + 0.000001)\n",
    "\n",
    "\n",
    "print(\"Polarity Score:\", polarity_score)\n",
    "print(\"Subjective Score:\",subjectivity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7b6d2",
   "metadata": {},
   "source": [
    "# NUMBER OF SENTENCES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5e97de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nWe have seen a huge development and dependence of people on technology in recent years.',\n",
       " 'We have also seen the development of AI and ChatGPT in recent years.',\n",
       " 'So it is a normal thing that we will become fully dependent on technology by 2040.',\n",
       " 'Information technology will be a major power for all the developing nations.',\n",
       " 'As a member of a developing nation, India is rapidly growing its IT base.',\n",
       " 'It has also grown some IT cities which will be the major control centres for Information technology by 2040.',\n",
       " 'Rising IT cities\\n\\nNoida:- Noida in Uttar Pradesh near New Delhi is an emerging IT sector now.',\n",
       " 'Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here.',\n",
       " 'Noida has a market base of billions of dollars and is doing a great job of boosting the national economy.',\n",
       " 'The establishment of so many software companies has made Noida an information technology hub.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sentences = sent_tokenize(article_text)\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9133d190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541ecb3",
   "metadata": {},
   "source": [
    "# AVERAGE NUMBER OF WORDS PER SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be7aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.166666666666666\n"
     ]
    }
   ],
   "source": [
    "average_num_of_wrds_persent= len(words_after_sw) /len(sentences)\n",
    "print(average_num_of_wrds_persent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0caa581",
   "metadata": {},
   "source": [
    "# AVERAGE WORD LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69cddfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_char_in_each_word(words_after_sw):\n",
    "    sum=0\n",
    "    for word in words_after_sw:\n",
    "        sum=sum+len(word)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f69af8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##example testing :\n",
    "ex_sentence=\"We have seen how things work in NLP and now it's time to work on projects !!\"\n",
    "ex_words=word_tokenize(ex_sentence)\n",
    "ex_words_after_sw = [word for word in ex_words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dd47aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seen', 'things', 'work', 'NLP', \"'s\", 'time', 'work', 'projects', '!', '!']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_words_after_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42dc4eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length:3.7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average word length:{sum_of_char_in_each_word(ex_words_after_sw)/len(ex_words_after_sw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd15b83",
   "metadata": {},
   "source": [
    "# remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb0397dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    pattern = r'[^\\w\\s]'\n",
    "    # Replace punctuation with an empty string\n",
    "    clean_sentence = re.sub(pattern, '', sentence)\n",
    "    return clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5edb0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have seen how things work in NLP and now its time to work on projects \n"
     ]
    }
   ],
   "source": [
    "clean_sent=remove_punctuation(ex_sentence)\n",
    "print(clean_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3bc10",
   "metadata": {},
   "source": [
    "# sent ex_sentence to remove punctuation and now again to avg word length: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a9da9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seen', 'things', 'work', 'NLP', 'time', 'work', 'projects']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words=word_tokenize(clean_sent)\n",
    "clean_words_after_sw = [word for word in clean_words if word.lower() not in stop_words]\n",
    "clean_words_after_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e134140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length:4.714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average word length:{sum_of_char_in_each_word(clean_words_after_sw)/len(clean_words_after_sw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab15c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
